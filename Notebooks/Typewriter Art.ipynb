{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan is to create ASCII like art, using the benefits that a typewriter offers, but being aware of it's limitations. Namely, we can overlay characters to multiply the # of glyphs But, we have limited options to begin with, ie. no |@#\n",
    "\n",
    "Process:\n",
    "- Input image, desired output size, and directory of glyph images\n",
    "    - Sub-division of letter spaces, as well as # glyphs per space\n",
    "- Image is converted to greyscale, and scaled to output size\n",
    "- Preprocess glyphs, making greyscale & scaled to sub-division\n",
    "    - I THINK that scaling to eg 3x3 would be the same as doing manual averages\n",
    "        - !Want to check this!\n",
    "        - Current theory is this is what BOX resampling would achieve for us\n",
    "    - If >1 glyph per space, calculate composite glyphs (This scales scarily)\n",
    "- From the image, take blocks of pixels, the 'target'\n",
    "    - Iterate through all the glyphs, working out 'distance' from target\n",
    "        - Don't forget the black space 'glyph'\n",
    "        - Distance metric likely to be N dimensional pythagorean distance (RMS)\n",
    "    - Closest glyph gets chosen, repeat for all targets\n",
    "- Render preview of design, using the original glyph images\n",
    "    - Monospace REALLY helps with this (25 x 48)\n",
    "- Produce instruction set to replicate on the typewriter\n",
    "    - Developing a nice notation here will be useful to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CURRENT PROBLEMS\n",
    "\n",
    "- Currently treating glyphs as if they were square, need to adjust this so that the image doesn't end up being stretched vertically\n",
    "    - Could treat the glyphs (25x48) as 1x2 in scale\n",
    "    - This is a good approximation, but would be hardcoded\n",
    "    - One option would just be to prestretch the image the other way\n",
    "\n",
    "- Currently we're scaling image to full range of our glyphs.\n",
    "    - This fixes the issues related to have thin glyphs on small SAMPLE_X values\n",
    "    - However, for higher SAMPLE_X, we can end up making the image darker?\n",
    "    - Contrast vs Brightness (Perhaps a ranking system rather than Euc distance?)\n",
    "    \n",
    "- Image may look MUCH better, if shifted by 1 sample width\n",
    "    - May want to iterate over, shifting the image, and summing the distances\n",
    "    - This'd give us a metric of 'best match'\n",
    "    - Test case would be an image made from glyphs, but shifted a little\n",
    "        - off anything other than exactly a # of sample widths wouldn't help though\n",
    "        - Can't check for each and every pixel offset\n",
    "\n",
    "\n",
    "- Old fill_range was broken, fixed that\n",
    "    - new fill range produces even more junky images\n",
    "    - Before, was clipping a lot of lighter colors to 255\n",
    "    - Now only lightest goes to 255, makes everything bleh\n",
    "    \n",
    "    - old was ```lambda val: ((val-min_) * (t_max/max_))+ t_min```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.219631910324097\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageChops, ImageOps\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.spatial import cKDTree\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "GLYPH_DIR = 'E:/Users/Richard/Documents/One off mini projects/Typewriting/Typearter/Glyphs'\n",
    "SAMPLE_X = 3  # 3x3 taken from the source glyph\n",
    "SAMPLE_Y = 3\n",
    "TARGET_WIDTH = 60\n",
    "TARGET_HEIGHT = 60  # This and width will come from image dimensions, or will affect that through cropping\n",
    "\n",
    "def fill_range(image, range_):\n",
    "    # Scales image colors to fill range_\n",
    "    # May not be fully warrented hard to say\n",
    "    min_, max_ = image.getextrema()\n",
    "    t_min, t_max = range_\n",
    "    range_ = max_ - min_\n",
    "    t_range = t_max - t_min\n",
    "    image =  image.point(lambda val: ((val-min_)* (t_range/range_))+t_min)\n",
    "    return image\n",
    "\n",
    "class glyph:\n",
    "    def __init__(self, name=None, image=None):\n",
    "        self.name = name\n",
    "        self.image = image\n",
    "        self.fingerprint = self.image.convert(\"L\")\\\n",
    "        .resize((SAMPLE_X, SAMPLE_Y), Image.BOX)\n",
    "        self.fingerdisplay = self.fingerprint.resize(self.image.size)\n",
    "        \n",
    "    @classmethod\n",
    "    def from_file(cls, filename):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        image = Image.open(os.path.join(GLYPH_DIR, filename))\n",
    "        return cls(name, image)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, glyph):\n",
    "            raise TypeError('can only combine glyph (not \"{}\") with glyph'.format(type(other)))\n",
    "        name = self.name + '&' + other.name\n",
    "        composite = ImageChops.darker(self.image, other.image)\n",
    "        return glyph(name, composite) \n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "def chunk(list_, width, chunk_width, chunk_height):\n",
    "    # Given an sequence, width, a chunk width, and chunk height\n",
    "    # Will return a list of 'chunks' of length chunk width * chunk height\n",
    "    # [0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F], 4, 2, 2\n",
    "    # 0 1 2 3\n",
    "    # 4 5 6 7\n",
    "    # 8 9 A B\n",
    "    # C D E F\n",
    "    # Would chunk to:\n",
    "    # [[0,1,4,5], [2,3,6,7], [8,9,C,D], [A,B,E,F]]\n",
    "    chunks = []\n",
    "    height = len(list_) // (width*chunk_height*chunk_width)\n",
    "    for y in range(height):\n",
    "        rows = range(chunk_height*y, chunk_height*(y+1))\n",
    "        for x in range(width):\n",
    "            columns = range(chunk_width*x, chunk_width*(x+1))\n",
    "            chunk = [list_[column + row*width*chunk_width]\\\n",
    "                     for row in rows for column in columns]\n",
    "            chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "def fit_to_aspect(image, aspect_ratio):\n",
    "    # Crops the image around the center to fit aspect ratio\n",
    "    current_aspect = image.width/image.height\n",
    "    if current_aspect < desired_aspect:  # Image too tall\n",
    "        perfect_height = image.width / desired_aspect\n",
    "        edge = (image.height - perfect_height) /2\n",
    "        image = image.crop((0, edge, image.width, perfect_height+edge))\n",
    "    else:  # Image too wide\n",
    "        perfect_width = image.height * desired_aspect\n",
    "        edge = (image.width - perfect_width) /2\n",
    "        image = image.crop((edge, 0, perfect_width+edge, image.height))\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def load_glyphs(directory):\n",
    "    glyphs = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".png\"):\n",
    "            glyph_ = glyph.from_file(filename)\n",
    "            glyphs.update({glyph_.name: glyph_})\n",
    "    return glyphs\n",
    "            \n",
    "def average_glyph_value(glyphs):\n",
    "    # Takes a dict of glyphs, and returns a list of average values\n",
    "    average_values = []\n",
    "    for name, glyph in glyphs.items():\n",
    "        vals = list(glyph.fingerprint.getdata())\n",
    "        average_value = sum(vals)/len(vals)  # May want to change to int division\n",
    "        average_values.append(average_value)\n",
    "    return average_values\n",
    "\n",
    "def lightest_color(glyphs):\n",
    "    lightest = 0\n",
    "    for name, glyph in glyphs.items():\n",
    "        dark, light = glyph.fingerprint.getextrema()\n",
    "        lightest = max(light, lightest)\n",
    "    return lightest\n",
    "        \n",
    "start = time.time()\n",
    "\n",
    "glyphs = load_glyphs(GLYPH_DIR)\n",
    "        \n",
    "combination_glyphs = combinations(iter(glyphs.values()), 2)\n",
    "for first, second in combination_glyphs:\n",
    "    combination = first + second\n",
    "    glyphs.update({combination.name:combination})\n",
    "    \n",
    "blank = Image.new(\"L\", (25,48), 'white')\n",
    "space = glyph(name='space', image=blank)\n",
    "glyphs.update({'space':space})\n",
    "lightest_value = 255  # need to unhardcode\n",
    "\n",
    "glyph_list = list(glyphs.values())\n",
    "glyph_data = [list(glyph.fingerprint.getdata()) for glyph in glyph_list]\n",
    "tree = cKDTree(glyph_data)\n",
    "\n",
    "def find_closest_glyph(target):\n",
    "    dd, ii = tree.query(section)\n",
    "    return glyph_list[ii]\n",
    "\n",
    "average_vals = average_glyph_value(glyphs)\n",
    "lightest_value = max(average_vals)\n",
    "darkest_value = min(average_vals)\n",
    "\n",
    "def equalize_glyph(image, mask=None):\n",
    "    # Manipulates image histogram to closely resemble that of glyphs\n",
    "    h = image.histogram(mask)\n",
    "    target_indices = []\n",
    "    for i in range(256):\n",
    "        count = average_vals.count(i)\n",
    "        if count:\n",
    "            target_indices.extend([i]*count)\n",
    "\n",
    "    histo = [_f for _f in h if _f]\n",
    "    step = (functools.reduce(operator.add, histo) - histo[-1]) // len(target_indices)\n",
    "            \n",
    "    lut = []\n",
    "    n = step//2\n",
    "    for i in range(256):\n",
    "        position = min(n//step, len(target_indices)-1)\n",
    "        lut.append(target_indices[position])\n",
    "        n += h[i]\n",
    "    \n",
    "    return image.point(lut)\n",
    "\n",
    "TARGET_IMAGE = 'E:/Users/Richard/Documents/One off mini projects/Typewriting/Typearter/dog.png'\n",
    "dog = Image.open(TARGET_IMAGE)\n",
    "\n",
    "desired_aspect = 25/48  # unhardcode\n",
    "dog = fit_to_aspect(dog, desired_aspect)\n",
    "    \n",
    "dog.show()\n",
    "\n",
    "# Changing the resampling mode here changes how the image ends up\n",
    "smol_dog = dog.resize((TARGET_WIDTH * SAMPLE_X, TARGET_HEIGHT * SAMPLE_Y), Image.LANCZOS)\n",
    "smol_dog = smol_dog.convert(\"L\")\n",
    "\n",
    "# Some ImageOps may help with color reproduction\n",
    "#smol_dog = ImageOps.autocontrast(smol_dog, cutoff=0)\n",
    "#smol_dog = ImageOps.equalize(smol_dog)\n",
    "#smol_dog = fill_range(smol_dog, (darkest_value, lightest_value))\n",
    "#smol_dog = equalize_glyph(smol_dog)\n",
    "smol_dog = fill_range(smol_dog, (150, 245))\n",
    "\n",
    "target_parts = chunk(list(smol_dog.getdata()), width=TARGET_WIDTH,\n",
    "                     chunk_width=SAMPLE_X, chunk_height=SAMPLE_Y)\n",
    "\n",
    "result = []\n",
    "\n",
    "for section in target_parts:   \n",
    "    result.append(find_closest_glyph(section))\n",
    "    \n",
    "calculation = Image.new(\"L\", (TARGET_WIDTH * 25, TARGET_HEIGHT * 48))\n",
    "output = Image.new(\"L\", (TARGET_WIDTH * 25, TARGET_HEIGHT  * 48))\n",
    "\n",
    "for i, glyph_ in enumerate(result):\n",
    "    w = 25\n",
    "    h = 48\n",
    "    x = w * (i % TARGET_WIDTH)\n",
    "    y = h * (i // TARGET_WIDTH)\n",
    "    calculation.paste(glyph_.fingerdisplay, (x, y, x + w, y + h))\n",
    "    output.paste(glyph_.image, (x, y, x + w, y + h))\n",
    "\n",
    "calculation.show()\n",
    "output.show()\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "average_vals = []\n",
    "sub_values = []\n",
    "for i, glyph_ in glyphs.items():\n",
    "    vals = list(glyph_.fingerprint.getdata())\n",
    "    average_val = sum(vals)//len(vals)\n",
    "#     print(glyph_.name + ': '+str(average_val))\n",
    "    average_vals.append(average_val)\n",
    "    sub_values.extend(vals)\n",
    "    \n",
    "section_vals = []\n",
    "    \n",
    "for section in target_parts:\n",
    "    average = sum(section)//len(section)\n",
    "    section_vals.append(average)\n",
    "    \n",
    "fig1 = plt.figure(figsize=(18,16))\n",
    "l, = plt.plot(np.linspace(0, 1, len(average_vals)), sorted(average_vals), 'rx-')\n",
    "l, = plt.plot(np.linspace(0, 1, len(section_vals)), sorted(section_vals), 'bx-')\n",
    "l, = plt.plot(np.linspace(0, 1, len(sub_values)), sorted(sub_values), 'gx-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLAYING WITH ENHANCEMENTS, TRYING TO MATCH OLD 'LOOK'\n",
    "\n",
    "from PIL import ImageEnhance, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testdog = dog.convert(\"L\").resize((300,600))\n",
    "\n",
    "#testdog.show()\n",
    "t_min = darkest_value\n",
    "t_max = lightest_value\n",
    "min_, max_ = testdog.getextrema()\n",
    "range_ = max_ - min_\n",
    "t_range = t_max - t_min\n",
    "old_dog = testdog.point(lambda val: ((val-min_) * (t_max/max_))+ t_min)\n",
    "new_dog =  testdog.point(lambda val: ((val-min_)* (t_range/range_))+t_min)\n",
    "\n",
    "equal_dog = ImageOps.equalize(testdog)\n",
    "\n",
    "contrast = ImageEnhance.Contrast(new_dog)\n",
    "e_dog = contrast.enhance(2.5)\n",
    "brightness = ImageEnhance.Brightness(e_dog)\n",
    "b_dog = brightness.enhance(1.3)\n",
    "\n",
    "equal_scale = fill_range(equal_dog, (t_min, t_max))\n",
    "\n",
    "%matplotlib inline\n",
    "f, axarr = plt.subplots(2, 6, figsize=(16,8))\n",
    "axarr[0][0].imshow(testdog.convert(\"RGB\"))\n",
    "axarr[0][1].imshow(old_dog.convert(\"RGB\"))\n",
    "axarr[0][2].imshow(new_dog.convert(\"RGB\"))\n",
    "axarr[0][3].imshow(b_dog.convert(\"RGB\"))\n",
    "axarr[0][4].imshow(equal_dog.convert(\"RGB\"))\n",
    "axarr[0][5].imshow(equal_scale.convert(\"RGB\"))\n",
    "\n",
    "axarr[1][0].hist(list(testdog.getdata()))\n",
    "axarr[1][1].hist(list(old_dog.getdata()))\n",
    "axarr[1][2].hist(list(new_dog.getdata()))\n",
    "axarr[1][3].hist(list(b_dog.getdata()))\n",
    "axarr[1][4].hist(list(equal_dog.getdata()))\n",
    "axarr[1][5].hist(list(equal_scale.getdata()))\n",
    "\n",
    "subhist = []\n",
    "for i in range(255):\n",
    "    subhist.append(sub_values.count(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
